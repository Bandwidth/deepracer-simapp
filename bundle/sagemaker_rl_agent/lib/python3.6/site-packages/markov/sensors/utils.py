'''This module houses all utility methods for the sensor module'''
import math
import numpy as np
import random
import cv2
import uuid
import logging
from PIL import Image, ImageFilter, ImageDraw

from markov.environments.constants import (
    TRAINING_IMAGE_SIZE, TRAINING_LIDAR_SIZE,
    NUMBER_OF_LIDAR_SECTORS
)

from markov.architecture.constants import SchemeInfo, Input, ActivationFunctions, NeuralNetwork
from markov.log_handler.deepracer_exceptions import GenericError
from markov.boto.s3.constants import ModelMetadataKeys
from rl_coach.spaces import StateSpace, ImageObservationSpace, \
                            VectorObservationSpace, PlanarMapsObservationSpace
from markov.log_handler.logger import Logger

LOG = Logger(__name__, logging.INFO).get_logger()

def get_observation_space(sensor, model_metadata=None):
    '''Creates the observation space for the given sensor
       sensor - String with the desired sensor to add to the
                observation space
        model_metadata - model metadata information
    '''
    obs = StateSpace({})

    if not isinstance(sensor, str):
        raise GenericError("None string type for sensor type: {}".format(type(sensor)))

    if sensor == Input.CAMERA.value or sensor == Input.OBSERVATION.value or \
    sensor == Input.LEFT_CAMERA.value:
        obs[sensor] = ImageObservationSpace(shape=np.array((TRAINING_IMAGE_SIZE[1],
                                                            TRAINING_IMAGE_SIZE[0],
                                                            3)),
                                            high=255,
                                            channels_axis=-1)
    elif sensor == Input.STEREO.value:
        obs[sensor] = PlanarMapsObservationSpace(shape=np.array((TRAINING_IMAGE_SIZE[1],
                                                                 TRAINING_IMAGE_SIZE[0],
                                                                 2)),
                                                 low=0,
                                                 high=255,
                                                 channels_axis=-1)
    elif sensor == Input.LIDAR.value:
        obs[sensor] = VectorObservationSpace(shape=TRAINING_LIDAR_SIZE, low=0.15, high=1.0)
    elif sensor == Input.SECTOR_LIDAR.value:
        obs[sensor] = VectorObservationSpace(shape=NUMBER_OF_LIDAR_SECTORS, low=0.0, high=1.0)
    elif sensor == Input.DISCRETIZED_SECTOR_LIDAR.value:
        lidar_config = model_metadata[ModelMetadataKeys.LIDAR_CONFIG.value]
        shape = lidar_config[ModelMetadataKeys.NUM_SECTORS.value] * \
                lidar_config[ModelMetadataKeys.NUM_VALUES_PER_SECTOR.value]
        obs[sensor] = VectorObservationSpace(shape=shape,
                                             low=0.0,
                                             high=1.0)
    else:
        raise Exception("Unable to set observation space for sensor {}".format(sensor))
    return obs

#! TODO currently left and front camera use the same embedders, this is how it is wired up
# in custom architectures, decide if this is the best way forward based on current experiments
def get_front_camera_embedders(network_type):
    '''Utility method for retrieving the input embedder for the front camera sensor, this
       needs to be in the util module due to the sagemaker/robomaker incompatibility
       network_type - The type of network for which to return the embedder for
    '''
    if not isinstance(network_type, str):
        raise GenericError("None string type for network type: {}".format(type(network_type)))

    input_embedder = dict()
    if network_type == NeuralNetwork.DEEP_CONVOLUTIONAL_NETWORK_SHALLOW.value:
        input_embedder = {Input.CAMERA.value:
                          {SchemeInfo.CONV_INFO_LIST.value: [[32, 8, 4], [64, 4, 2], [64, 3, 1]],
                           SchemeInfo.DENSE_LAYER_INFO_LIST.value: [],
                           SchemeInfo.BN_INFO_CONV.value: [False, ActivationFunctions.RELU.value,
                                                           0.0],
                           SchemeInfo.BN_INFO_DENSE.value: [False, ActivationFunctions.RELU.value,
                                                            0.0],
                           SchemeInfo.IS_FIRST_LAYER_BN.value: False}}
    elif network_type == NeuralNetwork.DEEP_CONVOLUTIONAL_NETWORK.value:
        input_embedder = {Input.CAMERA.value:
                          {SchemeInfo.CONV_INFO_LIST.value: [[32, 5, 2], [32, 3, 1],
                                                             [64, 3, 2], [64, 3, 1]],
                           SchemeInfo.DENSE_LAYER_INFO_LIST.value: [64],
                           SchemeInfo.BN_INFO_CONV.value: [False, ActivationFunctions.TANH.value,
                                                           0.0],
                           SchemeInfo.BN_INFO_DENSE.value: [False, ActivationFunctions.TANH.value,
                                                            0.0],
                           SchemeInfo.IS_FIRST_LAYER_BN.value: False}}
    elif network_type == NeuralNetwork.DEEP_CONVOLUTIONAL_NETWORK_DEEP.value:
        input_embedder = {Input.CAMERA.value:
                          {SchemeInfo.CONV_INFO_LIST.value: [[32, 8, 4], [32, 4, 2],
                                                             [64, 4, 2], [64, 3, 1]],
                           SchemeInfo.DENSE_LAYER_INFO_LIST.value: [512, 512],
                           SchemeInfo.BN_INFO_CONV.value: [True, ActivationFunctions.RELU.value,
                                                           0.0],
                           SchemeInfo.BN_INFO_DENSE.value: [False, ActivationFunctions.RELU.value,
                                                            0.5],
                           SchemeInfo.IS_FIRST_LAYER_BN.value: False}}
    else:
        raise Exception("Camera sensor has no embedder for topology {}".format(network_type))
    return input_embedder

def get_observation_embedder():
    '''Input embedders for the v1.0 simapp'''
    return {Input.OBSERVATION.value:
            {SchemeInfo.CONV_INFO_LIST.value: [[32, 8, 4], [64, 4, 2], [64, 3, 1]],
             SchemeInfo.DENSE_LAYER_INFO_LIST.value: [],
             SchemeInfo.BN_INFO_CONV.value: [False, ActivationFunctions.RELU.value, 0.0],
             SchemeInfo.BN_INFO_DENSE.value: [False, ActivationFunctions.RELU.value, 0.0],
             SchemeInfo.IS_FIRST_LAYER_BN.value: False}}

def get_left_camera_embedders(network_type):
    '''Utility method for retrieving the input embedder for the left camera sensor, this
       needs to be in the util module due to the sagemaker/robomaker incompatibility
       network_type - The type of network for which to return the embedder for
    '''
    if not isinstance(network_type, str):
        raise GenericError("None string type for network type: {}".format(type(network_type)))

    input_embedder = dict()
    if network_type == NeuralNetwork.DEEP_CONVOLUTIONAL_NETWORK_SHALLOW.value:
        input_embedder = {Input.LEFT_CAMERA.value:
                          {SchemeInfo.CONV_INFO_LIST.value: [[32, 8, 4], [64, 4, 2], [64, 3, 1]],
                           SchemeInfo.DENSE_LAYER_INFO_LIST.value: [],
                           SchemeInfo.BN_INFO_CONV.value: [False, ActivationFunctions.RELU.value,
                                                           0.0],
                           SchemeInfo.BN_INFO_DENSE.value: [False, ActivationFunctions.RELU.value,
                                                            0.0],
                           SchemeInfo.IS_FIRST_LAYER_BN.value: False}}
    elif network_type == NeuralNetwork.DEEP_CONVOLUTIONAL_NETWORK.value:
        input_embedder = {Input.LEFT_CAMERA.value:
                          {SchemeInfo.CONV_INFO_LIST.value: [[32, 5, 2], [32, 3, 1], [64, 3, 2],
                                                             [64, 3, 1]],
                           SchemeInfo.DENSE_LAYER_INFO_LIST.value: [64],
                           SchemeInfo.BN_INFO_CONV.value: [False, ActivationFunctions.TANH.value,
                                                           0.0],
                           SchemeInfo.BN_INFO_DENSE.value: [False, ActivationFunctions.TANH.value,
                                                            0.3],
                           SchemeInfo.IS_FIRST_LAYER_BN.value: False}}
    elif network_type == NeuralNetwork.DEEP_CONVOLUTIONAL_NETWORK_DEEP.value:
        input_embedder = {Input.LEFT_CAMERA.value:
                          {SchemeInfo.CONV_INFO_LIST.value: [[32, 8, 4], [32, 4, 2], [64, 4, 2],
                                                             [64, 3, 1]],
                           SchemeInfo.DENSE_LAYER_INFO_LIST.value: [512, 512],
                           SchemeInfo.BN_INFO_CONV.value: [True, ActivationFunctions.RELU.value,
                                                           0.0],
                           SchemeInfo.BN_INFO_DENSE.value: [False, ActivationFunctions.RELU.value,
                                                            0.0],
                           SchemeInfo.IS_FIRST_LAYER_BN.value: False}}
    else:
        raise Exception("Left camera sensor has no embedder for topology {}".format(network_type))
    return input_embedder

def get_stereo_camera_embedders(network_type):
    '''Utility method for retrieving the input embedder for the stereo camera sensor, this
       needs to be in the util module due to the sagemaker/robomaker incompatibility
       network_type - The type of network for which to return the embedder for
    '''
    if not isinstance(network_type, str):
        raise GenericError("None string type for network type: {}".format(type(network_type)))
    input_embedder = dict()
    if network_type == NeuralNetwork.DEEP_CONVOLUTIONAL_NETWORK_SHALLOW.value:
        input_embedder = {Input.STEREO.value:
                          {SchemeInfo.CONV_INFO_LIST.value: [[32, 8, 4], [64, 4, 2], [64, 3, 1]],
                           SchemeInfo.DENSE_LAYER_INFO_LIST.value: [],
                           SchemeInfo.BN_INFO_CONV.value: [False, ActivationFunctions.RELU.value,
                                                           0.0],
                           SchemeInfo.BN_INFO_DENSE.value: [False, ActivationFunctions.RELU.value,
                                                            0.0],
                           SchemeInfo.IS_FIRST_LAYER_BN.value: False}}
    #! TODO decide if we want to have a deep-deep topology that differes from deep
    elif network_type == NeuralNetwork.DEEP_CONVOLUTIONAL_NETWORK.value \
        or network_type == NeuralNetwork.DEEP_CONVOLUTIONAL_NETWORK_DEEP.value:
        input_embedder = {Input.STEREO.value:
                          {SchemeInfo.CONV_INFO_LIST.value: [[32, 3, 1], [64, 3, 2], [64, 3, 1],
                                                             [128, 3, 2], [128, 3, 1]],
                           SchemeInfo.DENSE_LAYER_INFO_LIST.value: [],
                           SchemeInfo.BN_INFO_CONV.value: [False, ActivationFunctions.RELU.value,
                                                           0.0],
                           SchemeInfo.BN_INFO_DENSE.value: [False, ActivationFunctions.RELU.value,
                                                            0.0],
                           SchemeInfo.IS_FIRST_LAYER_BN.value: False}}
    else:
        raise Exception("Stereo camera sensor has no embedder for topology {}".format(network_type))
    return input_embedder

def get_lidar_embedders(network_type, lidar_type):
    '''Utility method for retrieving the input embedder for the lidar camera sensor, this
       needs to be in the util module due to the sagemaker/robomaker incompatibility
       network_type - The type of network for which to return the embedder for
    '''
    #! TODO decide whether we need lidar layers for different network types
    input_embedder = {lidar_type:
                      {SchemeInfo.CONV_INFO_LIST.value: [],
                       SchemeInfo.DENSE_LAYER_INFO_LIST.value: [256, 256],
                       SchemeInfo.BN_INFO_CONV.value: [False, ActivationFunctions.RELU.value, 0.0],
                       SchemeInfo.BN_INFO_DENSE.value: [False, ActivationFunctions.RELU.value,
                                                        0.0],
                       SchemeInfo.IS_FIRST_LAYER_BN.value: False}}
    return input_embedder


def _rotate_image(image, angle):
    """
    Rotates an OpenCV 2 / NumPy image about it's centre by the given angle
    (in degrees). The returned image will be large enough to hold the entire
    new image, with a black background
    """

    # Get the image size
    # No that's not an error - NumPy stores image matricies backwards
    image_size = (image.shape[1], image.shape[0])
    image_center = tuple(np.array(image_size) / 2)

    # Convert the OpenCV 3x2 rotation matrix to 3x3
    rot_mat = np.vstack(
        [cv2.getRotationMatrix2D(image_center, angle, 1.0), [0, 0, 1]]
    )

    rot_mat_notranslate = np.matrix(rot_mat[0:2, 0:2])

    # Shorthand for below calcs
    image_w2 = image_size[0] * 0.5
    image_h2 = image_size[1] * 0.5

    # Obtain the rotated coordinates of the image corners
    rotated_coords = [
        (np.array([-image_w2,  image_h2]) * rot_mat_notranslate).A[0],
        (np.array([ image_w2,  image_h2]) * rot_mat_notranslate).A[0],
        (np.array([-image_w2, -image_h2]) * rot_mat_notranslate).A[0],
        (np.array([ image_w2, -image_h2]) * rot_mat_notranslate).A[0]
    ]

    # Find the size of the new image
    x_coords = [pt[0] for pt in rotated_coords]
    x_pos = [x for x in x_coords if x > 0]
    x_neg = [x for x in x_coords if x < 0]

    y_coords = [pt[1] for pt in rotated_coords]
    y_pos = [y for y in y_coords if y > 0]
    y_neg = [y for y in y_coords if y < 0]

    right_bound = max(x_pos)
    left_bound = min(x_neg)
    top_bound = max(y_pos)
    bot_bound = min(y_neg)

    new_w = int(abs(right_bound - left_bound))
    new_h = int(abs(top_bound - bot_bound))

    # We require a translation matrix to keep the image centred
    trans_mat = np.matrix([
        [1, 0, int(new_w * 0.5 - image_w2)],
        [0, 1, int(new_h * 0.5 - image_h2)],
        [0, 0, 1]
    ])

    # Compute the tranform for the combined rotation and translation
    affine_mat = (np.matrix(trans_mat) * np.matrix(rot_mat))[0:2, :]

    # Apply the transform
    result = cv2.warpAffine(
        image,
        affine_mat,
        (new_w, new_h),
        flags=cv2.INTER_LINEAR
    )

    return result


def _largest_rotated_rect(w, h, angle):
    """
    Given a rectangle of size wxh that has been rotated by 'angle' (in
    radians), computes the width and height of the largest possible
    axis-aligned rectangle within the rotated rectangle.

    Original JS code by 'Andri' and Magnus Hoff from Stack Overflow

    Converted to Python by Aaron Snoswell
    """

    quadrant = int(math.floor(angle / (math.pi / 2))) & 3
    sign_alpha = angle if ((quadrant & 1) == 0) else math.pi - angle
    alpha = (sign_alpha % math.pi + math.pi) % math.pi

    bb_w = w * math.cos(alpha) + h * math.sin(alpha)
    bb_h = w * math.sin(alpha) + h * math.cos(alpha)

    gamma = math.atan2(bb_w, bb_w) if (w < h) else math.atan2(bb_w, bb_w)

    delta = math.pi - alpha - gamma

    length = h if (w < h) else w

    d = length * math.cos(alpha)
    a = d * math.sin(alpha) / math.sin(delta)

    y = a * math.cos(gamma)
    x = y * math.tan(gamma)

    return (
        bb_w - 2 * x,
        bb_h - 2 * y
    )


def _crop_around_center(image, width, height):
    """
    Given a NumPy / OpenCV 2 image, crops it to the given width and height,
    around it's centre point
    """

    image_size = (image.shape[1], image.shape[0])
    image_center = (int(image_size[0] * 0.5), int(image_size[1] * 0.5))

    if(width > image_size[0]):
        width = image_size[0]

    if(height > image_size[1]):
        height = image_size[1]

    x1 = int(image_center[0] - width * 0.5)
    x2 = int(image_center[0] + width * 0.5)
    y1 = int(image_center[1] - height * 0.5)
    y2 = int(image_center[1] + height * 0.5)

    return image[y1:y2, x1:x2]


def uniform(low,hi):
    return low + random.random() * (hi - low)

def add_random_noise(image, iteration):

    #
    # PIL Image modifications
    #

    wall_cutoff = 140
    screen_width = 640

    if True: #(random.random() < 0.5):
        # Rotate the image
        image = image.rotate(uniform(-2.0,2.0))

    if True: #(random.random() < 0.5):
        # Blur the image
        image = image.filter(ImageFilter.GaussianBlur(uniform(0.0,2.0)))

    return image

